{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改 Tensor 的 `requires_grad` 参数将其变成可求导的神经元。该参数可在创建 Tensor 时修改，也可使用`.requires_grad_()`修改。\n",
    "* 注意：只有`float`类型的 Tensor 可以求导。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2,2,requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x+2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用`requires_grad=True`的 Tensor 来赋值的 Tensor 都可以求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看`grad_fn`属性，以检查该神经元是以什么函数的导数公式进行求导。在这里 y 是使用加法的规则求导。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AddBackward0 at 0x7f4a3612eef0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) \n",
      " tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()    #取一个 Tensor 中所有元素的平均值\n",
    "print(z,'\\n',out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从计算结束的地方开始反向传播`.backward()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用`.grad`查看反向传播后某处的梯度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用`.norm()`查看矩阵的 L2 范数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.4772)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = torch.tensor([\n",
    "    [1,2],\n",
    "    [3,4]],\n",
    "    dtype=torch.float,\n",
    ")\n",
    "h.norm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**深入理解`.backward()`方法**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.backward()`的第一个参数为`gradient`,也就是说，神经元会把下游传回来的梯度存起来，并作为`.backward()`方法的`gradient`参数，其实也就是前面提到的`.grad`属性。这个值默认是 1，pyton的广播机制将它变成一个合适维度的矩阵。如果我们希望给它赋予一个`grad`作为下游传回来地梯度时，可以在`.backward()`方法中添加一个`gradient`矩阵作为参数。\n",
    "* 注意:该`gradient`矩阵的维度需要和 Tensor 完全相同。\n",
    "* 链式法则使用的是矩阵乘法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]], requires_grad=True) tensor(1., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "grad = 4*torch.ones(4,4,dtype=torch.float)\n",
    "b = torch.ones(4,4, requires_grad=True)\n",
    "c = (b*b).mean()\n",
    "print(b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.backward(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8., 8., 8., 8.],\n",
      "        [8., 8., 8., 8.],\n",
      "        [8., 8., 8., 8.],\n",
      "        [8., 8., 8., 8.]])\n"
     ]
    }
   ],
   "source": [
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用`torch.no_grad()`方法创建一个过程，在这个过程里面所有的 Tensor 在进行**数学计算**之前`requires_grad`都会被置为`False`,因而计算的结果也是不可求导的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    q=x**2\n",
    "    print(q.requires_grad)\n",
    "    print(x.requires_grad)\n",
    "\n",
    "print(q.requires_grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里简单谈谈`with`语句地意思，`with`后面跟着对象，该对象至少拥有两个方法，一个是开启某状态的方法，另一个是关闭该状态的方法。在`with`块里面的命令都在这种状态开启的情况下运行，运行完这个代码块后该状态会自动关闭。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
